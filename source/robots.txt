# robots.txt Configuration File

# Basic rules applicable to all web crawlers
User-agent: *
# Allowed paths
Allow: /  # Homepage
Allow: /archives/  # Archive pages
Allow: /tags/  # Tag pages
Allow: /categories/  # Category pages
Allow: /about/  # About page

# Disallowed paths
Disallow: /js/  # JavaScript file directory
Disallow: /css/  # CSS file directory
Disallow: /img/  # Image resource directory (usually images are referenced by pages)

# Special rules for Baidu Spider
User-agent: Baiduspider
# Allow access to all pages (subject to the above Disallow rules)
Allow: /
# Provide a dedicated sitemap for Baidu Spider
Sitemap: https://tutorial.zen-harmony.top/baidusitemap.xml

# General sitemap applicable to all crawlers (may be overridden by specific crawler rules)
# Note: Some crawlers may prioritize rules set specifically for them over general rules
Sitemap: https://tutorial.zen-harmony.top/sitemap.xml
